{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 信息的定量描述\n",
    "直观理解： \n",
    "若消息发生的概率很大，受信者事先已经有所估计，则该消息的信息量就很小。 \n",
    "若消息发生的概率很小，受信者感觉到很突然，该消息所含有的信息量就很大。 \n",
    "所以信息量和概率联系在了一起，信息量可以表示为概率的函数。那么怎样的函数可以用来描述信息量呢？函数f(p)f(p)应该满足以下条件： \n",
    "1. f(p)应该是概率p的严格单调递减函数， \n",
    "2. 当p=1时，f(p)=0 \n",
    "3. 当p=0时，f(p)=∞\n",
    "4. 两个独立事件的联合信息量应该等于它们信息量之和。 \n",
    "以下是f(p)=−log(p)f(p)=−log(p)的图像，满足以上的所有的要求。\n",
    "--------------------- \n",
    "作者：_席达_ \n",
    "来源：CSDN \n",
    "原文：https://blog.csdn.net/robin_Xu_shuai/article/details/74011205 \n",
    "版权声明：本文为博主原创文章，转载请附上博文链接！\n",
    "\n",
    "\n",
    "# ID3算法熵计算公式\n",
    "\n",
    "1. 选择分类\\\\(x_i\\\\)的概率\n",
    "\n",
    "2. 信息期望值\n",
    "\n",
    "自信息和熵的定义\n",
    "若一个消息xx出现的概率为p，那么这个消息所含有的信息量为 \n",
    "$$I=−log(p)$$\n",
    "\n",
    "上式称为消息x的自信息，自信息有两种含义： \n",
    "1. 当该消息发生之前，表示发生该消息的不确定性， \n",
    "2. 当该消息发生之后，表示消息所含有的信息量。 \n",
    "信源含有的信息量是信源发出的所有可能消息的平均不确定性，香农把信源所含有的信息量称为熵，是指每个符号所含有的信息量（自信息）的统计平均。若X是一个离散随机变量，概率分布为\\\\(p(x)=P(X=x)\\\\),\\\\(x∈X\\\\)，那么XX的熵为 \n",
    "$$H(X)=\\sum_{i}^{N}p(xi)I(xi)=−\\sum_{i}^{N}p(xi)logp(xi)$$\n",
    "\n",
    "\n",
    "$$H(X)=-\\sum_{i=1}^{n}p(x_i)log_2p(x_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "def calcShannonEnt(dataSet):\n",
    "  numEntries = len(dataSet) #数据集长度\n",
    "  labelCounts = {}\n",
    "  for featVec in dataSet: #对数据集内所有判别式初始化为0\n",
    "    currentLabel = featVec[-1] #区每组数据尾部作为最终判别标签\n",
    "    if currentLabel not in labelCounts.keys():\n",
    "      labelCounts[currentLabel] = 0\n",
    "    labelCounts[currentLabel] += 1\n",
    "  shannonEnt = 0.0 #香农熵\n",
    "  for key in labelCounts:\n",
    "    prob = float(labelCounts[key])/numEntries  #计算每个类标签的出现概率\n",
    "    shannonEnt -= prob * log(prob,2) \n",
    "  return shannonEnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 不浮出水面是否可以生存 | 是否有蹼 | 鱼   |\n",
    "| ---------------------- | -------- | ---- |\n",
    "| yes                    | yes      | yes  |\n",
    "| yes                    | yes      | yes  |\n",
    "| yes                    | no       | no   |\n",
    "| no                     | yes      | no   |\n",
    "| no                     | no       | no   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "  dataSet = [\n",
    "    [1,1,'yes'],\n",
    "    [1,1,'yes'],\n",
    "    [1,0,'no'],\n",
    "    [0,1,'no'],\n",
    "    [0,1,'no']\n",
    "  ]\n",
    "  labels = ['no surfacing','flippers']\n",
    "  return dataSet,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 按照给定特征划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet,axis,value):\n",
    "  retDataSet = []\n",
    "  for featVec in dataSet:\n",
    "    if featVec[axis] == value:\n",
    "      reducedFeatVec = featVec[:axis]\n",
    "      reducedFeatVec.extend(featVec[axis+1:])\n",
    "      retDataSet.append(reducedFeatVec)\n",
    "  return retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "0.9709505944546686\n",
      "[[1, 'yes'], [1, 'yes'], [0, 'no']] \n",
      " [[1, 'no'], [1, 'no']]\n"
     ]
    }
   ],
   "source": [
    "myDat,labels = createDataSet()\n",
    "print(myDat)\n",
    "sn = calcShannonEnt(myDat)\n",
    "print(sn)\n",
    "x1 = splitDataSet(myDat,0,1)\n",
    "x2 = splitDataSet(myDat,0,0)\n",
    "print(x1,'\\n',x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 选择最好的数据集划分方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain, bestFeature = 0.0,-1\n",
    "    for i in range(numFeatures):\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals :\n",
    "            subDataSet = splitDataSet(dataSet,i,value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        print('infoGain=',infoGain,'bestFeature=',i,baseEntropy,newEntropy)\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet,labels):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel:{}}\n",
    "    del(labels[bestFeat])\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet,bestFeat,value),subLabels)\n",
    "    return myTree\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(inputTree,featLabels,testVec):\n",
    "    firstStr = inputTree.keys()[0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    key = testVec[featIndex]\n",
    "    valueofFeat = secondDict[key]\n",
    "    print('+++',firstStr,'xxx',secondDict,'---',key,'>>>',valueofFeat)\n",
    "    if isinstance(valueofFeat,dict):\n",
    "        classLabel = classify(valueofFeat,featLabels,testVec)\n",
    "    else:\n",
    "        classLabel = valueofFeat\n",
    "    return  classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infoGain= 0.4199730940219749 bestFeature= 0 0.9709505944546686 0.5509775004326937\n",
      "infoGain= 0.17095059445466854 bestFeature= 1 0.9709505944546686 0.8\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-3b81b3490b97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmyTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyDat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-c4b2c27e4309>\u001b[0m in \u001b[0;36mcreateTree\u001b[1;34m(dataSet, labels)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmajorityCnt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mbestFeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchooseBestFeatureToSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mbestFeatLabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbestFeat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mmyTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mbestFeatLabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbestFeat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "myTree = createTree(myDat,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
