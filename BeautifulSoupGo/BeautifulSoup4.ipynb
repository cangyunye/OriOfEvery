{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬虫-Beautiful Soup细说\n",
    "> [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/) 是一个可以从HTML或XML文件中提取数据的\n",
    ">\n",
    "> Python库.它能够通过你喜欢的转换器实现惯用的文档导航,查找,修改文档的方式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主流解析器\n",
    "| 解析器           | 使用方法                                                     | 优势                                                  | 劣势                                            |\n",
    "| ---------------- | ------------------------------------------------------------ | ----------------------------------------------------- | ----------------------------------------------- |\n",
    "| Python标准库     | `BeautifulSoup(markup, \"html.parser\")`                       | Python的内置标准库执行速度适中文档容错能力强          | Python 2.7.3 or 3.2.2)前 的版本中文档容错能力差 |\n",
    "| lxml HTML 解析器 | `BeautifulSoup(markup, \"lxml\")`                              | 速度快文档容错能力强                                  | 需要安装C语言库                                 |\n",
    "| lxml XML 解析器  | `BeautifulSoup(markup, [\"lxml-xml\"])``BeautifulSoup(markup, \"xml\")` | 速度快唯一支持XML的解析器                             | 需要安装C语言库                                 |\n",
    "| html5lib         | `BeautifulSoup(markup, \"html5lib\")`                          | 最好的容错性以浏览器的方式解析文档生成HTML5格式的文档 | 速度慢不依赖外部扩展                            |\n",
    "> 不同的解析器会在BeautifulSoup对象中由于HTML代码或XML代码不标准而生成不同的结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 快速开始\n",
    "以下这段HTML代码将会被经常使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造Beautifulsoup对象，使用python自带解析器html.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单的浏览结构化数据的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定位title标签\n",
    "soup.title\n",
    "# <title>The Dormouse's story</title>\n",
    "#title标签名\n",
    "soup.title.name\n",
    "# u'title'\n",
    "#title标签值\n",
    "soup.title.string\n",
    "# u'The Dormouse's story'\n",
    "#title标签父标签名\n",
    "soup.title.parent.name\n",
    "# u'head'\n",
    "#定位p标签\n",
    "soup.p\n",
    "# <p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "#p标签class属性的值\n",
    "soup.p['class']\n",
    "# u'title'\n",
    "#定位a标签\n",
    "soup.a\n",
    "# <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
    "#在BeautifulSoup对象中查询所有a节点\n",
    "soup.find_all('a')\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "#在BeautifulSoup对象中查询属性为id=\"link3\"的节点\n",
    "soup.find(id=\"link3\")\n",
    "# <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从文档中找到所有`<a>`标签的链接:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/elsie\n",
      "http://example.com/lacie\n",
      "http://example.com/tillie\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))\n",
    "    # http://example.com/elsie\n",
    "    # http://example.com/lacie\n",
    "    # http://example.com/tillie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从文档中获取所有文字内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Dormouse's story\n",
      "\n",
      "The Dormouse's story\n",
      "Once upon a time there were three little sisters; and their names were\n",
      "Elsie,\n",
      "Lacie and\n",
      "Tillie;\n",
      "and they lived at the bottom of a well.\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造BeautifulSoup对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file f:\\ProgramData\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "#从HTML文件读取内容\n",
    "# Soup = BeautifulSoup(open(\"index.html\"))\n",
    "#读取HTML格式的内容\n",
    "# Soup = BeautifulSoup(\"<html>data</html>\")\n",
    "#BeautifulSoup将HTML文档转换成Unicode格式,由于未指定解析器，会选择对应markup内容（即HTML代码部分）的最佳解析器\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\"><span>Elsie</span></a>\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\"><span>Lacie</span></a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\"><span>Tillie</span></a>\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 节点选择器\n",
    "通过直节点名称进行索引获取整个节点元素。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n",
      "<class 'bs4.element.Tag'>\n",
      "The Dormouse's story\n",
      "<head><title>The Dormouse's story</title></head>\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><span>Elsie</span></a>\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><span>Lacie</span></a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"><span>Tillie</span></a>\n",
      "and they lived at the bottom of a well.</p>\n"
     ]
    }
   ],
   "source": [
    "Soup = BeautifulSoup(html_doc,'lxml')\n",
    "#打印title节点\n",
    "print(Soup.title)\n",
    "#打印title属性的类型为Tag\n",
    "print(\"title节点的值:\",Soup.title.string)\n",
    "print(\"head节点:\",Soup.head)\n",
    "print(\"p节点:\",Soup.p)\n",
    "print(\"节点名称:\",Soup.title.name)\n",
    "print(\"p节点属性:\",Soup.p.attrs)\n",
    "print(\"p节点class属性:\",Soup.p.attrs[\"class\"])\n",
    "print(\"p节点class属性:\",Soup.p[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bs4.element.Tag是BeautifulSoup中的一个数据类型，用于表示节点元素，该属性包含多种常用方法如string获取属性值\n",
    "如上Soup.p预期输出p节点，p节点有多个，只会输出第一个匹配到的节点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取信息\n",
    "1. 获取名称\n",
    "2. 获取属性\n",
    "3. 获取内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "{'class': ['story']}\n",
      "['story']\n",
      "['story']\n"
     ]
    }
   ],
   "source": [
    "print(Soup.title.name)\n",
    "print(Soup.p.attrs)\n",
    "print(Soup.p.attrs[\"class\"])\n",
    "print(Soup.p[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌套选择\n",
    "在选择了一个节点后，可以继续选择其下级节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n"
     ]
    }
   ],
   "source": [
    "#先选择head节点，后选择title节点\n",
    "print(Soup.head.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关联选择\n",
    "我们也许选择一个独特的节点，但同时可能需要其他级，如父节点，兄弟节点，子节点信息\n",
    "### 子节点和子孙节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基点\n",
      " <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>\n",
      "None\n",
      "contents直接子节点:\n",
      " ['Once upon a time there were three little sisters; and their names were\\n', <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, ',\\n', <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, ' and\\n', <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>, ';\\nand they lived at the bottom of a well.']\n",
      "children直接子节点生成器:\n",
      " <list_iterator object at 0x000001BD01DF7518>\n",
      "children:\n",
      " ['Once upon a time there were three little sisters; and their names were\\n', <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, ',\\n', <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, ' and\\n', <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>, ';\\nand they lived at the bottom of a well.']\n",
      "descendants下级递归生成器:\n",
      " <generator object descendants at 0x000001BD01D81468>\n",
      "descendants:\n",
      " ['Once upon a time there were three little sisters; and their names were\\n', <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, 'Elsie', ',\\n', <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, 'Lacie', ' and\\n', <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>, 'Tillie', ';\\nand they lived at the bottom of a well.']\n"
     ]
    }
   ],
   "source": [
    "print(\"基点\\n\",Soup.p)\n",
    "#直接输入p下节点b\n",
    "print(Soup.p.b)\n",
    "#输入contents，返回直接子节点列表形式，不对子孙节点再划分\n",
    "print(\"contents直接子节点:\\n\",Soup.p.contents)\n",
    "#输入children，返回直接子节点生成器\n",
    "print(\"children直接子节点生成器:\\n\",Soup.p.children)\n",
    "print(\"children:\\n\",list(Soup.p.children))\n",
    "#输入descendants，返回向下级递归生成器,包含每个下级直到最终的值，含所有子孙节点\n",
    "print(\"descendants下级递归生成器:\\n\",Soup.p.descendants)\n",
    "print(\"descendants:\\n\",list(Soup.p.descendants))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 父节点和祖先节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基点\n",
      " <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><span>Elsie</span></a>\n",
      "父节点\n",
      " <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><span>Elsie</span></a>\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><span>Lacie</span></a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"><span>Tillie</span></a>\n",
      "and they lived at the bottom of a well.</p>\n",
      "父之父节点\n",
      " <body>\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><span>Elsie</span></a>\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><span>Lacie</span></a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"><span>Tillie</span></a>\n",
      "and they lived at the bottom of a well.</p>\n",
      "<p class=\"story\">...</p>\n",
      "</body>\n",
      "parents上级递归生成器点\n",
      " <generator object parents at 0x000001BD01DD38E0>\n"
     ]
    }
   ],
   "source": [
    "print(\"基点\\n\",Soup.a)\n",
    "#输入parent，a的父节点升级到其p节点\n",
    "print(\"父节点\\n\",Soup.a.parent)\n",
    "print(\"父之父节点\\n\",Soup.a.parent.parent)\n",
    "#输入parents，返回a的所有祖先节点\n",
    "print(\"parents上级递归生成器点\\n\",Soup.a.parents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 兄弟节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基点\n",
      " <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><span>Elsie</span></a>\n",
      "同级节点的下一个节点\n",
      " \n",
      "\n",
      "同级节点的下一个节点\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "print('基点\\n',Soup.a)\n",
    "print('同级节点的下一个节点\\n',Soup.a.next_sibling)\n",
    "print('同级节点的下一个节点\\n',Soup.a.previous_sibiling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next_sibling没匹配到，可以先用next_siblings查看，发现是先匹配了a标签后的\\n换行符，如果markup中的兄弟标签是一行写成则可以匹配到\n",
    "\n",
    "```<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><span>Elsie</span></a><a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><span>Lacie</span></a>```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "同级节点的后续节点生成器\n",
      " <generator object next_siblings at 0x000001BD01DD32B0>\n",
      "同级节点的前向节点生成器\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "print('同级节点的后续节点生成器\\n',Soup.a.next_siblings)\n",
    "print('同级节点的前向节点生成器\\n',Soup.a.previous_sibilings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法选择器\n",
    "使用方法：find_all(name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs)\n",
    "1. 根据节点名查询元素,返回列表形式，同时，列表元素为bs4.element.Tag类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "html = '''\n",
    "<div class=\"panel\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h4>Hello</h4>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "    <ul class=\"list\" id=\"list-1\">\n",
    "        <li class=\"element\">Foo</li>\n",
    "        <li class=\"element\">Bar</li>\n",
    "        <li class=\"element\">Jay</li>\n",
    "    </ul>\n",
    "    <ul class=\"list list-small\" id=\"list-2\">\n",
    "        <li class=\"element\">Foo</li>\n",
    "        <li class=\"element\">Bar</li>\n",
    "    </ul>\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "Soup = BeautifulSoup(html,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ul class=\"list\" id=\"list-1\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>, <ul class=\"list list-small\" id=\"list-2\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "</ul>]\n",
      "<class 'bs4.element.Tag'>\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>]\n",
      "Foo\n",
      "Bar\n",
      "Jay\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n",
      "Foo\n",
      "Bar\n"
     ]
    }
   ],
   "source": [
    "#name参数可以输入Tag,返回为列表元素为bs4.element.Tag，故继承Tag搜索方法\n",
    "print(Soup.find_all(name='ul'))\n",
    "print(type(Soup.find_all(name='ul')[0]))\n",
    "for ul in Soup.find_all(name='ul'):\n",
    "    print(ul.find_all(name='li'))\n",
    "    for li in ul.find_all(name='li'):\n",
    "        print(li.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ul class=\"list\" id=\"list-1\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>]\n"
     ]
    }
   ],
   "source": [
    "#attrs参数输入是字典类型，{属性:值}，返回列表元素为bs4.element.Tag\n",
    "print(Soup.find_all(attrs={'id':'list-1'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"hello,I'm study Machine Learning!\", \"hello,I'm study Deep Learning!\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text传入匹配节点的文本，可以是正则表达式，返回列表元素为bs4.element.Tag\n",
    "htmlZ='''\n",
    "<div class=\"panel\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h4>Hello</h4>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <a>hello,I'm study Machine Learning!</a>\n",
    "        <a>hello,I'm study Deep Learning!</a>\n",
    "    </div>\n",
    " </div>\n",
    "'''\n",
    "import re\n",
    "SoupZ=BeautifulSoup(htmlZ,'lxml')\n",
    "SoupZ.find_all(text=re.compile('Learning'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. find方法，返回单个bs4.element.Tag元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello,I'm study Machine Learning!\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SoupZ.find(text=re.compile('Learning'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其他方法：需要对bs4.element.Tag元素使用\n",
    "find_parents()返回所有祖先节点\n",
    "\n",
    "find_parent()返回父节点\n",
    "\n",
    "find_next_siblings()返回后面所有兄弟节点\n",
    "\n",
    "find_next_sibling()返回后面第一个兄弟节点\n",
    "\n",
    "find_previous_siblings()返回前面所有兄弟节点\n",
    "\n",
    "find_previous_sibling()返回前面第一个兄弟节点\n",
    "\n",
    "find_all_next()返回节点后所有符合条件的节点\n",
    "\n",
    "find_next()返回第一个符合条件的节点\n",
    "\n",
    "find_all_previous()返回节点所有符合条件的节点\n",
    "\n",
    "find_previous()返回第一个符合条件的节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a>hello,I'm study Machine Learning!</a>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SoupZ.find(text=re.compile('Learning')).find_previous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"panel-body\">\n",
       "<a>hello,I'm study Machine Learning!</a>\n",
       "<a>hello,I'm study Deep Learning!</a>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SoupZ.find(name='a').find_previous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.NavigableString"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(SoupZ.find(text=re.compile('Learning')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"panel-body\">\n",
       "<a>hello,I'm study Machine Learning!</a>\n",
       "<a>hello,I'm study Deep Learning!</a>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SoupZ.find(attrs={'class':\"panel-heading\"}).find_next_sibling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a>hello,I'm study Deep Learning!</a>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SoupZ.find(name='a').find_next_sibling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS选择器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = '''\n",
    "<div class=\"panel\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h4>Hello</h4>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "    <ul class=\"list\" id=\"list-1\">\n",
    "        <li class=\"element\">Foo</li>\n",
    "        <li class=\"element\">Bar</li>\n",
    "        <li class=\"element\">Jay</li>\n",
    "    </ul>\n",
    "    <ul class=\"list list-small\" id=\"list-2\">\n",
    "        <li class=\"element\">Foo</li>\n",
    "        <li class=\"element\">Bar</li>\n",
    "    </ul>\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "Soup = BeautifulSoup(html,'lxml')\n",
    "#关于CSS选择器，参考http://www.w3school.com.cn/cssref/css_selectors.asp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们仅调用select()方法，传入为CSS选择器\n",
    "`select(selector, _candidate_generator=None, limit=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"panel-heading\">\n",
      "<h4>Hello</h4>\n",
      "</div>]\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>, <li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "#selector=\".class\"，选择class=\"panel\"的类，再选择其下class=\"panel-heading\"\n",
    "print(Soup.select('.panel .panel-heading'))\n",
    "#选择标签ul之下li标签\n",
    "print(Soup.select('ul li'))\n",
    "#选择id=\"list-2\",class=\"element\"\n",
    "print(Soup.select('#list-2 .element'))\n",
    "#选择器返回的列表中，元素为bs4.element.Tag\n",
    "print(type(Soup.select('ul')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌套选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>]\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n"
     ]
    }
   ],
   "source": [
    "#选择所有ul节点后选择之下li节点\n",
    "for ul in Soup.select('ul'):\n",
    "    print(ul.select('li'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list-1\n",
      "list-2\n"
     ]
    }
   ],
   "source": [
    "#对Tag元素获取属性\n",
    "for attr in (map(lambda x:x['id'],Soup.select('ul'))):\n",
    "    print(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Text: Foo\n",
      "String: Foo\n",
      "Get Text: Bar\n",
      "String: Bar\n",
      "Get Text: Jay\n",
      "String: Jay\n",
      "Get Text: Foo\n",
      "String: Foo\n",
      "Get Text: Bar\n",
      "String: Bar\n"
     ]
    }
   ],
   "source": [
    "#get_text()或者string\n",
    "for li in Soup.select('li'):\n",
    "    print('Get Text:',li.get_text())\n",
    "    print('String:',li.string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
