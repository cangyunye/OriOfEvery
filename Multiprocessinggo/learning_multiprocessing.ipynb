{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing模块\n",
    "\n",
    "multiprocessing属于Python标准模块，支持多线程和多进程编写。\n",
    "\n",
    "## （一）为什么要使用多进程\n",
    "\n",
    "> Python语言中的全局解释器锁GIL限制了1个进程中，所有线程序列化执行，即执行1个线程的同时，并不能执行另一个线程，但支持异步执行。\n",
    "Multiprocessing可以充分调动CPU多核心优势，开启多进程处理。\n",
    "\n",
    "## （二）multiprocessing常用函数\n",
    "\n",
    "创建管理进程模块：\n",
    "\n",
    "- Process（用于创建进程模块）\n",
    "- Pool（用于创建管理进程池）\n",
    "- Queue（用于进程通信，资源共享）\n",
    "- Value，Array（用于进程通信，资源共享）\n",
    "- Pipe（用于管道通信）\n",
    "- Manager（用于资源共享）\n",
    "\n",
    "同步子进程模块：\n",
    "\n",
    "- Condition\n",
    "- Event\n",
    "- Lock\n",
    "- RLock\n",
    "- Semaphore\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    "> 创建一个Process实例，创建子进程时，target指定一个执行函数，args指定函数的参数\n",
    "\n",
    "> 用start()方法启动，join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent process 10512.\n",
      "Child process will start.\n",
      "Child process end.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import os\n",
    "\n",
    "\n",
    "def run_proc(name):\n",
    "    print('Run child process %s (%s)...' % (name, os.getpid()))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Parent process %s.' % os.getpid())\n",
    "    p1 = Process(target=run_proc, args=('test', ))\n",
    "    print('Child process will start.')\n",
    "    p1.start()\n",
    "    p1.join()\n",
    "    print('Child process end.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码块中的内容需要保存为py文件后执行才能使`__main__`正确引用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Init! 10384\n",
      "Run End\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import os\n",
    "\n",
    "\n",
    "def run_n(number):\n",
    "    print(\"Now we run process{} with pid {}\".format(number, os.getpid()))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 进程列表\n",
    "    procs = []\n",
    "    print(\"Run Init!\", os.getpid())\n",
    "    for number in range(10):\n",
    "        proc = Process(target=run_n, args=(number, ))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    "\n",
    "    for proc in procs:\n",
    "        proc.join()  # 等待进程结束\n",
    "    print(\"Run End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果未指定Process的target参数，则默认运行Process.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`if __name__ == '__main__':`是必要的\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 环境与启动方法\n",
    "\n",
    "-  [`multiprocessing`](https://docs.python.org/release/3.7.2/library/multiprocessing.html?highlight=multiprocessing#module-multiprocessing) 支持三种方法启动，且依赖于平台。\n",
    "\n",
    "  > - ***spawn***\n",
    "  >\n",
    "  >   父进程重启一个新的python进程, 子进程只继承运行进程对象所必要的资源[`run()`](https://docs.python.org/release/3.7.2/library/multiprocessing.html?highlight=multiprocessing#multiprocessing.Process.run) 方法.尤其是不必要的文件描述符和父进程的句柄不会被继承。比起使用*fork* or *forkserver*，使用这个方法会比较慢.兼容 Unix and Windows。 默认为Windows。\n",
    "  >\n",
    "  > - ***fork***\n",
    "  >\n",
    "  >   父进程通过 [`os.fork()`](https://docs.python.org/release/3.7.2/library/os.html#os.fork) 分叉一个Python解释器。 子进程完全和父进程相同。所有父进程资源都会继承到子进程。需要注意的是，想安全的分叉多线程的进程可能存在问题。只有Unix允许使用。\n",
    "  >\n",
    "  > - ***forkserver***\n",
    "  >\n",
    "  >   无论何时需要加入新进程，那么父进程会接入服务器请求分叉一个新进程。分叉服务器是单行线程，所以使用[`os.fork()`](https://docs.python.org/release/3.7.2/library/os.html#os.fork)会比较安全。非必要的资源不会继承，可以支持在Unix管道上传递文件描述符的Unix平台。\n",
    "\n",
    "\n",
    "\n",
    "在 `if __name__ == '__main__'` 使用 [`set_start_method()`](https://docs.python.org/release/3.7.2/library/multiprocessing.html?highlight=multiprocessing#multiprocessing.set_start_method) 选择一个启动方法。在一个程序中，仅使用一次。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def foo(q):\n",
    "    q.put('hello')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mp.set_start_method('spawn')\n",
    "    q = mp.Queue()\n",
    "    p = mp.Process(target=foo, args=(q,))\n",
    "    p.start()\n",
    "    print(q.get())\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 另外, 也可以选择 [`get_context()`](https://docs.python.org/release/3.7.2/library/multiprocessing.html?highlight=multiprocessing#multiprocessing.get_context) ，使用方法同上，但二者仅取一。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def foo(q):\n",
    "    q.put('hello')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ctx = mp.get_context('spawn')\n",
    "    q = ctx.Queue()\n",
    "    p = ctx.Process(target=foo, args=(q,))\n",
    "    p.start()\n",
    "    print(q.get())\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进程中替换对象\n",
    "\n",
    "multiprocessing支持两种类型间的进程通讯。\n",
    "\n",
    "## Queues\n",
    "Queue.qsize()    返回队列的大小\n",
    "\n",
    "Queue.empty()    如果队列为空，返回True,反之False\n",
    "\n",
    "Queue.full()     如果队列满了，返回True,反之False\n",
    "\n",
    "Queue.full 与 maxsize 大小对应\n",
    "\n",
    "Queue.get([block[, timeout]]) 获取队列，timeout是等待时间\n",
    "\n",
    "Queue.get_nowait()            相当Queue.get(False)\n",
    "\n",
    "Queue.put(item)               写入队列，timeout是等待时间\n",
    "\n",
    "Queue.put_nowait(item)        相当Queue.put(item, False)\n",
    "\n",
    "Queue.task_done()             在完成一项工作之后，Queue.task_done()函数向任务已经完成的队列发送一个信号\n",
    "\n",
    "Queue.join()                  实际上意味着等到队列为空，再执行别的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import os, time, random\n",
    "\n",
    "# 写数据进程执行的代码:\n",
    "def write(q):\n",
    "    print('Process to write: %s' % os.getpid())\n",
    "    for value in ['A', 'B', 'C']:\n",
    "        print('Put %s to queue...' % value)\n",
    "        q.put(value)\n",
    "        time.sleep(random.random())\n",
    "\n",
    "# 读数据进程执行的代码:\n",
    "def read(q):\n",
    "    print('Process to read: %s' % os.getpid())\n",
    "    while True:\n",
    "        value = q.get(True)\n",
    "        print('Get %s from queue.' % value)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # 父进程创建Queue，并传给各个子进程：\n",
    "    q = Queue()\n",
    "    pw = Process(target=write, args=(q,))\n",
    "    pr = Process(target=read, args=(q,))\n",
    "    # 启动子进程pw，写入:\n",
    "    pw.start()\n",
    "    # 启动子进程pr，读取:\n",
    "    pr.start()\n",
    "    # 等待pw结束:\n",
    "    pw.join()\n",
    "    # pr进程里是死循环，无法等待其结束，只能强行终止:\n",
    "    pr.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipes\n",
    "\n",
    "> Pipes()函数返回一对通过双向管道连接的对象。\n",
    "\n",
    "> 通过Pipe()连接的两个对象表示管道的两端。每个连接对象都有send()和recv()方法。 \n",
    "\n",
    "> 如果2个进程或线程同时对管道的尾端读取或写入可能导致管道的崩溃。 如果使用不同的管道尾端处理那就没有崩溃风险。\n",
    "\n",
    "发送对象必须满足序列化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "def f(conn):\n",
    "    conn.send([42, None, 'hello'])\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #构造Pipe的两端。\n",
    "    parent_conn, child_conn = Pipe()\n",
    "    p = Process(target=f, args=(child_conn,))\n",
    "    p.start()\n",
    "    print(parent_conn.recv())   # prints \"[42, None, 'hello']\"\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进程间同步\n",
    "\n",
    "## 进程锁\n",
    "\n",
    "Lock():为了保证在同一时间，多个进程使用共享资源不会被冲突，可以使用进程锁解决。\n",
    "\n",
    "acquire():锁定进程\n",
    "\n",
    "release():释放进程\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "#加进程锁\n",
    "def job(v, num, l):\n",
    "    l.acquire() # 锁住\n",
    "    for _ in range(5):\n",
    "        time.sleep(0.1) \n",
    "        v.value += num # 获取共享内存\n",
    "        print(v.value)\n",
    "    l.release() # 释放\n",
    "\n",
    "def multicore():\n",
    "    l = mp.Lock() # 定义一个进程锁\n",
    "    v = mp.Value('i', 0) # 定义共享内存\n",
    "    p1 = mp.Process(target=job, args=(v,1,l)) # 需要将lock传入\n",
    "    p2 = mp.Process(target=job, args=(v,3,l)) \n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multicore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不加进程锁\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "def job(v, num):\n",
    "    for _ in range(5):\n",
    "        time.sleep(0.1) # 暂停0.1秒，让输出效果更明显\n",
    "        v.value += num # v.value获取共享变量值\n",
    "        print(v.value, end=\"\")\n",
    "        \n",
    "def multicore():\n",
    "    v = mp.Value('i', 0) # 定义共享变量\n",
    "    p1 = mp.Process(target=job, args=(v,1))\n",
    "    p2 = mp.Process(target=job, args=(v,3)) # 设定不同的number看如何抢夺内存\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    multicore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果不用lock进行不同进程间输出控制，会导致冲突。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进程间状态共享\n",
    "\n",
    "如上所述，在同时执行程序时，需尽可能避免使用共享状态。\n",
    "\n",
    "当然，如果在某些情况确实需要使用到，也可使用如下几个方法。\n",
    "\n",
    "## 共享内存\n",
    "\n",
    "数据可以存储在共享内存中，使用Value()或者Array()方法映射。\n",
    "\n",
    "Array类，可以和共享内存交互，来实现在进程之间共享数据。它只能是一维的，不能是多维的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Value, Array\n",
    "\n",
    "def f(n, a):\n",
    "    n.value = 3.1415927\n",
    "    for i in range(len(a)):\n",
    "        a[i] = -a[i]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num = Value('d', 0.0)\n",
    "    arr = Array('i', range(10))\n",
    "\n",
    "    p = Process(target=f, args=(num, arr))\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "    print(num.value)\n",
    "    print(arr[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">在创建 `num` 和 `arr` 时使用的`i`,`d`是[`array`](https://docs.python.org/3.7/library/array.html#module-array) 模块的代码类型: `'d'`双倍精度浮点 ，`'i'` 表示有符整数。\n",
    ">\n",
    "> 更多其他用法参考 [`multiprocessing.sharedctypes`](https://docs.python.org/3.7/library/multiprocessing.html?highlight=process#module-multiprocessing.sharedctypes) 模块，支持任意ctypes对象分配共享内存。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Type code | C Type             | Python Type       | Minimum size in bytes | Notes |\n",
    "| --------- | ------------------ | ----------------- | --------------------- | ----- |\n",
    "| `'b'`     | signed char        | int               | 1                     |       |\n",
    "| `'B'`     | unsigned char      | int               | 1                     |       |\n",
    "| `'u'`     | Py_UNICODE         | Unicode character | 2                     | (1)   |\n",
    "| `'h'`     | signed short       | int               | 2                     |       |\n",
    "| `'H'`     | unsigned short     | int               | 2                     |       |\n",
    "| `'i'`     | signed int         | int               | 2                     |       |\n",
    "| `'I'`     | unsigned int       | int               | 2                     |       |\n",
    "| `'l'`     | signed long        | int               | 4                     |       |\n",
    "| `'L'`     | unsigned long      | int               | 4                     |       |\n",
    "| `'q'`     | signed long long   | int               | 8                     | (2)   |\n",
    "| `'Q'`     | unsigned long long | int               | 8                     | (2)   |\n",
    "| `'f'`     | float              | float             | 4                     |       |\n",
    "| `'d'`     | double             | float             | 8                     |       |\n",
    "\n",
    "Notes:\n",
    "\n",
    "1. `'u'`类型和Python的弃用的unicode字符 ([`Py_UNICODE`](https://docs.python.org/3.5/c-api/unicode.html#c.Py_UNICODE) which is `wchar_t`). 通过平台区分16bits或32bits.\n",
    "\n",
    "   `'u'`将在4.0版本从 [`Py_UNICODE`](https://docs.python.org/3.5/c-api/unicode.html#c.Py_UNICODE) API移除.\n",
    "\n",
    "2. `'q'` 和`'Q'`只有在支持用C编译器编译Python的平台支持C `long long`, 如果是在Windows上，则为`__int64`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 服务端进程\n",
    "\n",
    "> `Manager()`方法返回的一个管理对象，控制一个支持Python对象的服务端进程，使其他进程可以通过代理操作。\n",
    ">\n",
    "> 支持的类型： [`list`](https://docs.python.org/3.7/library/stdtypes.html#list), [`dict`](https://docs.python.org/3.7/library/stdtypes.html#dict), [`Namespace`](https://docs.python.org/3.7/library/multiprocessing.html?highlight=process#multiprocessing.managers.Namespace), [`Lock`](https://docs.python.org/3.7/library/multiprocessing.html?highlight=process#multiprocessing.Lock), [`RLock`](https://docs.python.org/3.7/library/multiprocessing.html?highlight=process#multiprocessing.RLock), [`Semaphore`](https://docs.python.org/3.7/library/multiprocessing.html?highlight=process#multiprocessing.Semaphore), [`BoundedSemaphore`](https://docs.python.org/3.7/library/multiprocessing.html?highlight=process#multiprocessing.BoundedSemaphore), [`Condition`](https://docs.python.org/3.7/library/multiprocessing.html?highlight=process#multiprocessing.Condition), [`Event`](https://docs.python.org/3.7/library/multiprocessing.html?highlight=process#multiprocessing.Event), [`Barrier`](https://docs.python.org/3.7/library/multiprocessing.html?highlight=process#multiprocessing.Barrier), [`Queue`](https://docs.python.org/3.7/library/multiprocessing.html?highlight=process#multiprocessing.Queue), [`Value`](https://docs.python.org/3.7/library/multiprocessing.html?highlight=process#multiprocessing.Value) , [`Array`](https://docs.python.org/3.7/library/multiprocessing.html?highlight=process#multiprocessing.Array). \n",
    ">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager\n",
    "\n",
    "def f(d, l):\n",
    "    d[1] = '1'\n",
    "    d['2'] = 2\n",
    "    d[0.25] = None\n",
    "    l.reverse()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Manager() as manager:\n",
    "        d = manager.dict()\n",
    "        l = manager.list(range(10))\n",
    "\n",
    "        p = Process(target=f, args=(d, l))\n",
    "        p.start()\n",
    "        p.join()\n",
    "\n",
    "        print(d)\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进程池\n",
    "\n",
    "使用[`Pool`](https://docs.python.org/3.7/library/multiprocessing.html?highlight=process#multiprocessing.pool.Pool) 类表示一池的进程，提供方法允许多个任务从运行进程以不同方式做卸下处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, TimeoutError\n",
    "import time\n",
    "import os\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # start 4 worker processes\n",
    "    with Pool(processes=4) as pool:\n",
    "\n",
    "        # print \"[0, 1, 4,..., 81]\"\n",
    "        print(pool.map(f, range(10)))\n",
    "\n",
    "        # print same numbers in arbitrary order\n",
    "        for i in pool.imap_unordered(f, range(10)):\n",
    "            print(i)\n",
    "\n",
    "        # evaluate \"f(20)\" asynchronously\n",
    "        res = pool.apply_async(f, (20,))      # runs in *only* one process\n",
    "        print(res.get(timeout=1))             # prints \"400\"\n",
    "\n",
    "        # evaluate \"os.getpid()\" asynchronously\n",
    "        res = pool.apply_async(os.getpid, ()) # runs in *only* one process\n",
    "        print(res.get(timeout=1))             # prints the PID of that process\n",
    "\n",
    "        # launching multiple evaluations asynchronously *may* use more processes\n",
    "        multiple_results = [pool.apply_async(os.getpid, ()) for i in range(4)]\n",
    "        print([res.get(timeout=1) for res in multiple_results])\n",
    "\n",
    "        # make a single worker sleep for 10 secs\n",
    "        res = pool.apply_async(time.sleep, (10,))\n",
    "        try:\n",
    "            print(res.get(timeout=1))\n",
    "        except TimeoutError:\n",
    "            print(\"We lacked patience and got a multiprocessing.TimeoutError\")\n",
    "\n",
    "        print(\"For the moment, the pool remains available for more work\")\n",
    "\n",
    "    # exiting the 'with'-block has stopped the pool\n",
    "    print(\"Now the pool is closed and no longer available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 要注意，pool的方法只能被创建的进程使用。\n",
    "\n",
    ">For循环中执行步骤：\n",
    "\n",
    ">（1）循环遍历，将500个子进程添加到进程池（相对父进程会阻塞）\n",
    "\n",
    ">（2）每次执行4个子进程，等一个子进程执行完后，立马启动新的子进程。（相对父进程不阻塞）\n",
    "\n",
    "apply_async为异步进程池写法。即非阻塞异步指的是启动子进程的过程，与父进程本身的执行（print）是异步的，而For循环中往进程池添加子进程的过程，与父进程本身的执行却是同步的。\n",
    "\n",
    "对Pool对象调用join()方法会等待所有子进程执行完毕，\n",
    "调用join()之前必须先调用close()，\n",
    "调用close()之后就不能继续添加新的Process了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果要启动大量的子进程，可以用进程池的方式批量创建子进程：\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "def long_time_task(name):\n",
    "    print('Run task %s (%s)...' % (name, os.getpid()))\n",
    "    start = time.time()\n",
    "    time.sleep(random.random() * 3)\n",
    "    end = time.time()\n",
    "    print('Task %s runs %0.2f seconds.' % (name, (end - start)))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Parent process %s.' % os.getpid())\n",
    "    # 如何是基于CPU核数量\n",
    "    p = Pool(4)\n",
    "    for i in range(500):\n",
    "        p.apply_async(long_time_task, args=(i, ))\n",
    "    print('Waiting for all subprocesses done...')\n",
    "    p.close()\n",
    "    p.join()\n",
    "    print('All subprocesses done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">实际测试发现，for循环内部执行步骤：\n",
    "\n",
    ">（1）遍历500个可迭代对象，往进程池放一个子进程\n",
    "\n",
    ">（2）执行这个子进程，等子进程执行完毕，再往进程池放一个子进程，再执行。（同时只执行一个子进程）\n",
    "\n",
    ">for循环执行完毕，再执行print函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "def test(p):\n",
    "    print (p)\n",
    "    time.sleep(3)\n",
    "if __name__==\"__main__\":\n",
    "    pool = Pool(processes=10)\n",
    "    for i  in range(500):\n",
    "        pool.apply(test, args=(i,))   #维持执行的进程总数为10，当一个进程执行完后启动一个新进程.\n",
    "    print (\"test\")\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分布式进程\n",
    "\n",
    "参考廖雪峰python3 分布式进程\n",
    "\n",
    "在Thread和Process中，应当优选Process，因为Process更稳定，而且，Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上。\n",
    "\n",
    "Python的`multiprocessing`模块不但支持多进程，其中`managers`子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。由于`managers`模块封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。\n",
    "\n",
    "举个例子：如果我们已经有一个通过`Queue`通信的多进程程序在同一台机器上运行，现在，由于处理任务的进程任务繁重，希望把发送任务的进程和处理任务的进程分布到两台机器上。怎么用分布式进程实现？\n",
    "\n",
    "原有的`Queue`可以继续使用，但是，通过`managers`模块把`Queue`通过网络暴露出去，就可以让其他机器的进程访问`Queue`了。\n",
    "\n",
    "我们先看服务进程，服务进程负责启动`Queue`，把`Queue`注册到网络上，然后往`Queue`里面写入任务："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function <lambda> at 0x000002026FF31B70>: attribute lookup <lambda> on __main__ failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1d0944ec37da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mmanager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQueueManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mb'abc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# 启动Queue:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;31m# 获得通过网络访问的Queue对象:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_task_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\managers.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self, initializer, initargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mident\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_identity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;34m'-'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mident\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;31m# get address of server\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x000002026FF31B70>: attribute lookup <lambda> on __main__ failed"
     ]
    }
   ],
   "source": [
    "#task_master.py\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import random, time, queue\n",
    "from multiprocessing.managers import BaseManager\n",
    "\n",
    "# 发送任务的队列:\n",
    "task_queue = queue.Queue()\n",
    "# 接收结果的队列:\n",
    "result_queue = queue.Queue()\n",
    "\n",
    "# 从BaseManager继承的QueueManager:\n",
    "class QueueManager(BaseManager):\n",
    "    pass\n",
    "\n",
    "# 把两个Queue都注册到网络上, callable参数关联了Queue对象:\n",
    "QueueManager.register('get_task_queue', callable=lambda: task_queue)\n",
    "QueueManager.register('get_result_queue', callable=lambda: result_queue)\n",
    "# 绑定端口5000, 设置验证码'abc':\n",
    "manager = QueueManager(address=('', 5000), authkey=b'abc')\n",
    "# 启动Queue:\n",
    "manager.start()\n",
    "# 获得通过网络访问的Queue对象:\n",
    "task = manager.get_task_queue()\n",
    "result = manager.get_result_queue()\n",
    "# 放几个任务进去:\n",
    "for i in range(10):\n",
    "    n = random.randint(0, 10000)\n",
    "    print('Put task %d...' % n)\n",
    "    task.put(n)\n",
    "# 从result队列读取结果:\n",
    "print('Try get results...')\n",
    "for i in range(10):\n",
    "    r = result.get(timeout=10)\n",
    "    print('Result: %s' % r)\n",
    "# 关闭:\n",
    "manager.shutdown()\n",
    "print('master exit.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task_worker.py\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import time, sys\n",
    "from multiprocessing.managers import BaseManager\n",
    "\n",
    "# 创建类似的QueueManager:\n",
    "class QueueManager(BaseManager):\n",
    "    pass\n",
    "\n",
    "# 由于这个QueueManager只从网络上获取Queue，所以注册时只提供名字:\n",
    "QueueManager.register('get_task_queue')\n",
    "QueueManager.register('get_result_queue')\n",
    "\n",
    "# 连接到服务器，也就是运行task_master.py的机器:\n",
    "server_addr = '127.0.0.1'\n",
    "print('Connect to server %s...' % server_addr)\n",
    "# 端口和验证码注意保持与task_master.py设置的完全一致:\n",
    "m = QueueManager(address=(server_addr, 5000), authkey=b'abc')\n",
    "# 客户端从网络连接:\n",
    "m.connect()\n",
    "# 获取Queue的对象:\n",
    "task = m.get_task_queue()\n",
    "result = m.get_result_queue()\n",
    "# 从task队列取任务,并把结果写入result队列:\n",
    "for i in range(10):\n",
    "    try:\n",
    "        n = task.get(timeout=1)\n",
    "        print('run task %d * %d...' % (n, n))\n",
    "        r = '%d * %d = %d' % (n, n, n*n)\n",
    "        time.sleep(1)\n",
    "        result.put(r)\n",
    "    except Queue.Empty:\n",
    "        print('task queue is empty.')\n",
    "# 处理结束:\n",
    "print('worker exit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而`Queue`之所以能通过网络访问，就是通过`QueueManager`实现的。由于`QueueManager`管理的不止一个`Queue`，所以，要给每个`Queue`的网络调用接口起个名字，比如`get_task_queue`。\n",
    "\n",
    "`authkey`有什么用？这是为了保证两台机器正常通信，不被其他机器恶意干扰。如果`task_worker.py`的`authkey`和`task_master.py`的`authkey`不一致，肯定连接不上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "102px",
    "width": "270px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "257.425px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
