{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬虫-Beautiful Soup细说\n",
    "> [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/) 是一个可以从HTML或XML文件中提取数据的\n",
    ">\n",
    "> Python库.它能够通过你喜欢的转换器实现惯用的文档导航,查找,修改文档的方式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主流解析器\n",
    "| 解析器           | 使用方法                                                     | 优势                                                  | 劣势                                            |\n",
    "| ---------------- | ------------------------------------------------------------ | ----------------------------------------------------- | ----------------------------------------------- |\n",
    "| Python标准库     | `BeautifulSoup(markup, \"html.parser\")`                       | Python的内置标准库执行速度适中文档容错能力强          | Python 2.7.3 or 3.2.2)前 的版本中文档容错能力差 |\n",
    "| lxml HTML 解析器 | `BeautifulSoup(markup, \"lxml\")`                              | 速度快文档容错能力强                                  | 需要安装C语言库                                 |\n",
    "| lxml XML 解析器  | `BeautifulSoup(markup, [\"lxml-xml\"])``BeautifulSoup(markup, \"xml\")` | 速度快唯一支持XML的解析器                             | 需要安装C语言库                                 |\n",
    "| html5lib         | `BeautifulSoup(markup, \"html5lib\")`                          | 最好的容错性以浏览器的方式解析文档生成HTML5格式的文档 | 速度慢不依赖外部扩展                            |\n",
    "> 不同的解析器会在BeautifulSoup对象中由于HTML代码或XML代码不标准而生成不同的结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 快速开始\n",
    "以下这段HTML代码将会被经常使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造Beautifulsoup对象，使用python自带解析器html.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单的浏览结构化数据的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定位title标签\n",
    "soup.title\n",
    "# <title>The Dormouse's story</title>\n",
    "#title标签名\n",
    "soup.title.name\n",
    "# u'title'\n",
    "#title标签值\n",
    "soup.title.string\n",
    "# u'The Dormouse's story'\n",
    "#title标签父标签名\n",
    "soup.title.parent.name\n",
    "# u'head'\n",
    "#定位p标签\n",
    "soup.p\n",
    "# <p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "#p标签class属性的值\n",
    "soup.p['class']\n",
    "# u'title'\n",
    "#定位a标签\n",
    "soup.a\n",
    "# <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
    "#在BeautifulSoup对象中查询所有a节点\n",
    "soup.find_all('a')\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "#在BeautifulSoup对象中查询属性为id=\"link3\"的节点\n",
    "soup.find(id=\"link3\")\n",
    "# <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从文档中找到所有`<a>`标签的链接:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/elsie\n",
      "http://example.com/lacie\n",
      "http://example.com/tillie\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))\n",
    "    # http://example.com/elsie\n",
    "    # http://example.com/lacie\n",
    "    # http://example.com/tillie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从文档中获取所有文字内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Dormouse's story\n",
      "\n",
      "The Dormouse's story\n",
      "Once upon a time there were three little sisters; and their names were\n",
      "Elsie,\n",
      "Lacie and\n",
      "Tillie;\n",
      "and they lived at the bottom of a well.\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造BeautifulSoup对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'index.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d62bcdf83e00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#从HTML文件读取内容\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mSoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"index.html\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#读取HTML格式的内容\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mSoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<html>data</html>\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'index.html'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "#从HTML文件读取内容\n",
    "Soup = BeautifulSoup(open(\"index.html\"))\n",
    "#读取HTML格式的内容\n",
    "Soup = BeautifulSoup(\"<html>data</html>\")\n",
    "#BeautifulSoup将HTML文档转换成Unicode格式\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 节点选择器\n",
    "通过直节点名称进行索引获取整个节点元素。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n",
      "<class 'bs4.element.Tag'>\n",
      "The Dormouse's story\n",
      "<head><title>The Dormouse's story</title></head>\n",
      "<p class=\"title\"><b>The Dormouse's story</b></p>\n"
     ]
    }
   ],
   "source": [
    "Soup = BeautifulSoup(html_doc,'lxml')\n",
    "#打印title节点\n",
    "print(Soup.title)\n",
    "#打印title属性的类型为Tag\n",
    "print(type(Soup.title))\n",
    "print(Soup.title.string)\n",
    "print(Soup.head)\n",
    "print(Soup.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bs4.element.Tag是BeautifulSoup中的一个数据类型，用于表示节点元素，该属性包含多种常用方法如string获取属性值\n",
    "如上Soup.p预期输出p节点，p节点有多个，只会输出第一个匹配到的节点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取信息\n",
    "1. 获取名称\n",
    "2. 获取属性\n",
    "3. 获取内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "{'class': ['title']}\n",
      "['title']\n",
      "['title']\n"
     ]
    }
   ],
   "source": [
    "print(Soup.title.name)\n",
    "print(Soup.p.attrs)\n",
    "print(Soup.p.attrs[\"class\"])\n",
    "print(Soup.p[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌套选择\n",
    "在选择了一个节点后，可以继续选择其下级节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n"
     ]
    }
   ],
   "source": [
    "#先选择head节点，后选择title节点\n",
    "print(Soup.head.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关联选择\n",
    "我们也许选择一个独特的节点，但同时可能需要其他级，如父节点，兄弟节点，子节点信息\n",
    "1. 子节点和子孙节点\n",
    "2. 父节点和祖先节点\n",
    "3. 兄弟节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
      "<b>The Dormouse's story</b>\n",
      "contents:\n",
      " ['\\n', <p class=\"title\"><b>The Dormouse's story</b></p>, '\\n', <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>, '\\n', <p class=\"story\">...</p>, '\\n']\n",
      "<list_iterator object at 0x00000204199F6470>\n",
      "contents:\n",
      " ['\\n', <p class=\"title\"><b>The Dormouse's story</b></p>, '\\n', <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>, '\\n', <p class=\"story\">...</p>, '\\n']\n",
      "<generator object descendants at 0x00000204194C0F68>\n",
      "contents:\n",
      " ['\\n', <p class=\"title\"><b>The Dormouse's story</b></p>, <b>The Dormouse's story</b>, \"The Dormouse's story\", '\\n', <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>, 'Once upon a time there were three little sisters; and their names were\\n', <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, 'Elsie', ',\\n', <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, 'Lacie', ' and\\n', <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>, 'Tillie', ';\\nand they lived at the bottom of a well.', '\\n', <p class=\"story\">...</p>, '...', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print(Soup.p)\n",
    "#直接输入p下节点b\n",
    "print(Soup.p.b)\n",
    "#输入contents，返回直接子节点列表形式，不对子孙节点再划分\n",
    "print(\"contents:\\n\",Soup.body.contents)\n",
    "#输入children，返回直接子节点生成器\n",
    "print(Soup.body.children)\n",
    "print(\"contents:\\n\",list(Soup.body.children))\n",
    "#输入descendants，返回向下级递归生成器,包含每个下级直到最终的值，含所有子孙节点\n",
    "print(Soup.body.descendants)\n",
    "print(\"contents:\\n\",list(Soup.body.descendants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object descendants at 0x00000204199BCC50>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
